[
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html",
    "href": "posts/03-expected-value-loss-functions/index.html",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "",
    "text": "NoteWhat you’ll learn in 10 minutes\n\n\n\n\nExpected value is the bridge between probability distributions and the numbers you compute from data — and you’re already using it every time you evaluate a loss function.\nVariance measures spread around the mean, and it quietly controls everything from feature scaling to overfitting to how noisy your test accuracy is.\nEvery loss function is an expected value in disguise: MSE estimates \\(E[(Y-\\hat{Y})^2]\\) under Gaussian errors, cross-entropy estimates \\(-E[Y\\log\\hat{P} + \\ldots]\\) under Bernoulli targets, MAE targets the median under Laplace errors.\nWhen you pick a loss, you pick a distribution. When you train, you minimise an expected value. When you evaluate, you estimate one from a finite sample."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#you-already-use-expected-values.-you-just-dont-call-them-that.",
    "href": "posts/03-expected-value-loss-functions/index.html#you-already-use-expected-values.-you-just-dont-call-them-that.",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "You already use expected values. You just don’t call them that.",
    "text": "You already use expected values. You just don’t call them that.\nEvery time you compute an average, you’re computing an expected value. Every time you evaluate a loss function, you’re computing an expected value. Every time you report “my model’s accuracy is 91%,” that number is an expected value.\nThe concept hides behind so many familiar operations that most ML engineers never pause to examine it directly. That’s a problem, because expected value isn’t just a formula — it’s the bridge between probability distributions (which describe the world) and the numbers you compute from data (which summarise it).\nIn the previous article, we established that your data consists of realisations of random variables, and that your model learns a conditional distribution. Now the question is: once you have a distribution, what do you do with it? How do you extract a single useful number from an entire probability distribution?\nThe answer is expected value. And the specific expected values you’re already computing — without knowing it — are your loss functions."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#expected-value-the-long-run-average",
    "href": "posts/03-expected-value-loss-functions/index.html#expected-value-the-long-run-average",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Expected value: the long-run average",
    "text": "Expected value: the long-run average\nLet \\(X\\) be a random variable with some distribution. The expected value of \\(X\\), written \\(E[X]\\), is the average value you’d get if you could draw from that distribution infinitely many times.\nFor a discrete random variable with values \\(x_1, x_2, \\ldots\\) and probabilities \\(p_1, p_2, \\ldots\\):\n\\[E[X] = \\sum_i x_i \\, p_i\\]\nFor a continuous random variable with density \\(f(x)\\):\n\\[E[X] = \\int_{-\\infty}^{\\infty} x \\, f(x) \\, dx\\]\nBoth say the same thing: weight each possible value by how likely it is, and add them up.\n\nA concrete example\nRoll a fair die. The random variable \\(X\\) is the number that comes up. The expected value is:\n\\[E[X] = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} = 3.5\\]\nYou’ll never roll 3.5. That’s fine. The expected value isn’t a value you expect to see — it’s the centre of gravity of the distribution. It’s the number your sample mean converges to as you roll more and more times.\n\n\nExpected value of a function\nHere’s where things get powerful. You can take the expected value of any function of a random variable, not just \\(X\\) itself.\nIf \\(g(X)\\) is some function of \\(X\\), then:\n\\[E[g(X)] = \\sum_i g(x_i) \\, p_i \\quad \\text{(discrete)}\\]\n\\[E[g(X)] = \\int g(x) \\, f(x) \\, dx \\quad \\text{(continuous)}\\]\nThis is called the Law of the Unconscious Statistician (yes, really: the name is a gentle jab at people who use it without realising what they’re doing).\nWhy does this matter? Because loss functions are functions of random variables. And when you average a loss function over your data, you’re estimating the expected value of that function. Let’s make this precise."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#variance-how-spread-out-is-the-distribution",
    "href": "posts/03-expected-value-loss-functions/index.html#variance-how-spread-out-is-the-distribution",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Variance: how spread out is the distribution?",
    "text": "Variance: how spread out is the distribution?\nBefore we get to loss functions, we need one more concept. Variance measures how spread out a random variable is around its expected value:\n\\[\\text{Var}(X) = E\\left[(X - E[X])^2\\right]\\]\nRead it carefully. Variance is itself an expected value — the expected value of the squared deviation from the mean. It’s \\(E[g(X)]\\) where \\(g(X) = (X - \\mu)^2\\).\nThe square root of variance is the standard deviation, \\(\\sigma = \\sqrt{\\text{Var}(X)}\\), which has the same units as \\(X\\) and is easier to interpret.\nA useful alternative formula (derived by expanding the square):\n\\[\\text{Var}(X) = E[X^2] - (E[X])^2\\]\nThis tells you: the variance is the expected value of the square minus the square of the expected value. Or more memorably: “the mean of the squares minus the square of the mean.”\n\nWhy variance matters for ML\nVariance shows up everywhere:\nIn your data: The variance of your features determines how much information they carry. A feature with zero variance is useless: it tells you nothing. Feature scaling (standardisation) divides by standard deviation precisely to put all features on equal footing.\nIn your model: The variance of your model’s predictions across different training sets is what we call “model variance” in the bias-variance tradeoff. High variance means your model is sensitive to which specific data points it was trained on, that’s overfitting.\nIn your estimates: When you report “accuracy = 0.91”, that number has a variance. It would be different if you’d tested on a different sample. The variance tells you how much to trust it."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#covariance-when-random-variables-move-together",
    "href": "posts/03-expected-value-loss-functions/index.html#covariance-when-random-variables-move-together",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Covariance: when random variables move together",
    "text": "Covariance: when random variables move together\nWhen you have two random variables, you often want to know: do they tend to increase together, or does one go up when the other goes down?\nCovariance measures this:\n\\[\\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]\\]\nPositive covariance means they move together. Negative means they move in opposite directions. Zero covariance means there’s no linear relationship (but there could still be a nonlinear one).\nCorrelation is covariance normalised to lie between -1 and 1:\n\\[\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sqrt{\\text{Var}(X) \\cdot \\text{Var}(Y)}}\\]\nHere’s the ML connection that matters: multicollinearity happens when your feature variables have high covariance with each other. When features are highly correlated, your regression coefficients become unstable: they have high variance, are hard to interpret, and can flip sign. PCA, which we’ll cover in a future article, works by finding directions in feature space along which the variance is maximised while the covariance between the new directions is zero."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#now-the-connection-that-changes-everything",
    "href": "posts/03-expected-value-loss-functions/index.html#now-the-connection-that-changes-everything",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Now: the connection that changes everything",
    "text": "Now: the connection that changes everything\nHere’s the payoff. Let’s look at what you’re actually computing when you train a model.\nYou have training data \\(\\{(x_i, y_i)\\}_{i=1}^n\\). You have a model \\(\\hat{y} = f(x; \\theta)\\) with parameters \\(\\theta\\). You define a loss function \\(L(y, \\hat{y})\\) that measures how bad each prediction is. Then you compute:\n\\[\\hat{R}(\\theta) = \\frac{1}{n} \\sum_{i=1}^n L(y_i, f(x_i; \\theta))\\]\nThis is the empirical risk: the average loss over your training data. You minimise it to find the best parameters.\nBut what are you really doing? You’re computing a sample average of the function \\(L(y, f(x; \\theta))\\). And a sample average is an estimate of an expected value:\n\\[R(\\theta) = E[L(Y, f(X; \\theta))]\\]\nThis is the true risk: the expected loss over the entire data-generating distribution. It’s the quantity you actually care about, because it tells you how well your model will perform on new data, not just the training set.\nTraining is estimating parameters that minimise an expected value. Your loss function is the function inside that expectation.\nThis is not a metaphor. It’s literally what’s happening when you call model.fit()."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#loss-functions-are-expected-values-the-specifics",
    "href": "posts/03-expected-value-loss-functions/index.html#loss-functions-are-expected-values-the-specifics",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Loss functions are expected values: the specifics",
    "text": "Loss functions are expected values: the specifics\nLet’s make this concrete for the loss functions you use every day.\n\nMean Squared Error\n\\[\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\quad \\approx \\quad E\\left[(Y - \\hat{Y})^2\\right]\\]\nThe MSE is a sample estimate of the expected squared error. Notice that this looks exactly like the formula for variance, and that’s not a coincidence. If your model predicts the mean perfectly (\\(\\hat{Y} = E[Y|X]\\)), then the remaining MSE is the irreducible variance of \\(Y\\) given \\(X\\). That’s the noise in your data that no model can eliminate.\nHere’s the deeper insight: MSE is the natural loss function when you assume \\(Y|X \\sim \\mathcal{N}(\\hat{y}, \\sigma^2)\\). Minimising MSE is identical to maximising the likelihood under Gaussian errors. We’ll prove this formally in the next article on likelihood, but for now, know that choosing MSE means assuming your errors are normally distributed. If they’re not — if they’re skewed, heavy-tailed, or heteroscedastic — MSE may not be the right choice.\n\n\nMean Absolute Error\n\\[\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i| \\quad \\approx \\quad E\\left[|Y - \\hat{Y}|\\right]\\]\nMAE estimates the expected absolute error. Minimising MAE doesn’t correspond to Gaussian errors: it corresponds to Laplace (double exponential) errors. This is why MAE is more robust to outliers: the Laplace distribution has heavier tails than the Gaussian, so it’s less surprised by extreme values.\nThe best prediction under MAE is the conditional median of \\(Y|X\\), not the mean. This is a key distinction: MSE targets the mean, MAE targets the median. If your data is skewed, these are different numbers and the choice matters.\n\n\nCross-Entropy (Log Loss)\nFor binary classification with true labels \\(y_i \\in \\{0, 1\\}\\) and predicted probabilities \\(\\hat{p}_i\\):\n\\[\\text{CE} = -\\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\log \\hat{p}_i + (1-y_i)\\log(1 - \\hat{p}_i)\\right] \\quad \\approx \\quad -E\\left[Y\\log\\hat{P} + (1-Y)\\log(1-\\hat{P})\\right]\\]\nCross-entropy is the expected negative log-probability assigned to the true outcome. It’s what you get when you do maximum likelihood estimation for a Bernoulli distribution, which is exactly what logistic regression does.\nMinimising cross-entropy makes your predicted probabilities \\(\\hat{p}\\) as close as possible (in a precise information-theoretic sense) to the true conditional probability \\(P(Y=1|X)\\).\n\n\nThe unifying view\n\n\n\n\n\n\n\n\nWhat you compute\nWhat it estimates\nWhat it assumes\n\n\n\n\n\\(\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2\\)\n\\(E[(Y-\\hat{Y})^2]\\)\nGaussian errors\n\n\n\\(\\frac{1}{n}\\sum\\|y_i - \\hat{y}_i\\|\\)\n\\(E[\\|Y-\\hat{Y}\\|]\\)\nLaplace errors\n\n\n\\(-\\frac{1}{n}\\sum y_i \\log\\hat{p}_i + \\ldots\\)\n\\(-E[Y\\log\\hat{P} + \\ldots]\\)\nBernoulli targets\n\n\n\\(\\frac{1}{n}\\sum(y_i\\log\\frac{y_i}{\\hat{y}_i} - y_i + \\hat{y}_i)\\)\n\\(E\\left[Y\\log\\frac{Y}{\\hat{Y}} - Y + \\hat{Y}\\right]\\)\nPoisson targets\n\n\n\nEvery loss function in this table is a sample average estimating an expected value. Every one corresponds to a distributional assumption about your target variable. Every time you pick a loss function, you’re making a statistical assumption whether you intend to or not."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#properties-of-expected-value-that-make-ml-work",
    "href": "posts/03-expected-value-loss-functions/index.html#properties-of-expected-value-that-make-ml-work",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "Properties of expected value that make ML work",
    "text": "Properties of expected value that make ML work\nA few properties of \\(E[\\cdot]\\) are quietly holding the entire ML pipeline together:\nLinearity: \\(E[aX + bY] = aE[X] + bE[Y]\\)\nThis is why you can decompose complex losses into simpler components. It’s why regularised loss = data loss + penalty works mathematically. It’s why ensemble methods (averaging multiple models) reduce expected error.\nLaw of Large Numbers: As \\(n \\to \\infty\\), the sample mean \\(\\bar{X}_n \\to E[X]\\)\nThis is why training on more data works. Your empirical risk (sample average loss) converges to the true risk (expected loss) as your dataset grows. With enough data, the training loss becomes a reliable estimate of the test loss.\nIterated Expectation (Tower Law): \\(E[E[Y|X]] = E[Y]\\)\nThis says: if you first compute the expected value of \\(Y\\) within each group defined by \\(X\\), and then average those, you get the overall expected value of \\(Y\\). This is the mathematical foundation of the bias-variance decomposition, which we’ll derive in a future article."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#the-sample-mean-is-an-estimator-and-it-has-variance",
    "href": "posts/03-expected-value-loss-functions/index.html#the-sample-mean-is-an-estimator-and-it-has-variance",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "The sample mean is an estimator — and it has variance",
    "text": "The sample mean is an estimator — and it has variance\nWhen you compute \\(\\bar{x} = \\frac{1}{n}\\sum x_i\\) from data, you’re estimating \\(E[X]\\) from a finite sample. This estimate is itself a random variable: if you’d drawn different data, you’d get a different \\(\\bar{x}\\).\nThe variance of the sample mean is:\n\\[\\text{Var}(\\bar{X}) = \\frac{\\text{Var}(X)}{n}\\]\nThis one formula explains several things at once:\nWhy more data helps: As \\(n\\) increases, \\(\\text{Var}(\\bar{X})\\) decreases. Your estimate becomes more precise. This is why training on more data is almost always beneficial: you’re reducing the variance of your loss estimates.\nWhy your test accuracy fluctuates: If you evaluate on 100 test samples vs. 10,000, the variance of your accuracy estimate differs by a factor of 100. Small test sets give noisy estimates.\nWhy mini-batch SGD works: Each mini-batch gives you a noisy estimate of the gradient (which is itself an expected value). The variance of that estimate decreases with batch size. Smaller batches = noisier gradients = more variance but faster updates. Larger batches = smoother gradients = less variance but slower updates. The tradeoff is directly governed by \\(\\text{Var}(\\bar{X}) = \\text{Var}(X)/n\\)."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#what-this-means-in-practice",
    "href": "posts/03-expected-value-loss-functions/index.html#what-this-means-in-practice",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "What this means in practice",
    "text": "What this means in practice\nUnderstanding that loss functions are expected values gives you three practical capabilities:\n1. You can diagnose loss function mismatch. If your residuals are heavily skewed, MSE (which assumes Gaussian errors) is pulling your predictions toward a mean that isn’t representative. Switch to MAE (which targets the median) or a quantile loss. If your count data has overdispersion, Poisson deviance will underestimate uncertainty — consider negative binomial loss instead. The distributional assumption behind your loss function must match the actual behaviour of your data.\n2. You can understand why your evaluation metrics are noisy. Your reported accuracy, F1 score, or AUC are all sample averages estimating expected values. They have variance. Reporting them without confidence intervals is like reporting a point estimate without uncertainty: technically a number, practically meaningless. We’ll cover confidence intervals properly in a future article.\n3. You can reason about the bias-variance tradeoff. The expected test error decomposes into bias squared plus variance plus irreducible noise. All three terms are expected values. Understanding this decomposition requires understanding expected value first — which is why we’re building this foundation before tackling bias-variance directly."
  },
  {
    "objectID": "posts/03-expected-value-loss-functions/index.html#the-mental-model-to-take-away",
    "href": "posts/03-expected-value-loss-functions/index.html#the-mental-model-to-take-away",
    "title": "Expected Value, Variance, and Why Your Loss Function Is a Statistic",
    "section": "The mental model to take away",
    "text": "The mental model to take away\nBefore: “I pick MSE for regression and cross-entropy for classification because that’s what the tutorial said.”\nAfter: “MSE estimates \\(E[(Y - \\hat{Y})^2]\\) under a Gaussian assumption. Cross-entropy estimates \\(-E[Y\\log\\hat{P} + (1-Y)\\log(1-\\hat{P})]\\) under a Bernoulli assumption. I choose based on the distributional properties of my target variable — and I check whether those assumptions hold.”\nThat’s the shift. Loss functions aren’t arbitrary choices or convention. They’re expected values derived from specific distributional assumptions. When you pick a loss, you’re picking a distribution. When you train a model, you’re minimising an expected value. When you evaluate, you’re estimating an expected value from a finite sample.\nNext week, we’ll close the loop. You now know your data comes from distributions (article 2) and your training process minimises expected values of loss functions derived from those distributions (this article). The missing piece is: how exactly do you estimate the distribution’s parameters from data? That’s likelihood: the single most important concept in ML that nobody teaches properly.\n\nThis is article 3 of Stats Beneath, a weekly series on the statistical foundations of machine learning. Subscribe to get each article when it’s published."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html",
    "href": "posts/01-why-stats-matter/index.html",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "",
    "text": "Did you know?\n\nThe term “regression” comes from Francis Galton’s 1886 study on the heights of parents and children. He noticed that tall parents tended to have slightly shorter children, and short parents had slightly taller ones,they “regressed” toward the average. The name stuck, even though modern regression has nothing to do with shrinking.\n\nThere’s a pattern I see everywhere. Someone discovers machine learning, gets excited, installs scikit-learn or tidymodels, runs a random forest on a dataset, and gets 94% accuracy. Amazing! Ship it!\nBut then someone asks: “Why did your model predict that?” And the answer is… silence.\nThis is what happens when we skip the foundation. Machine learning is not magic,it’s statistics at scale. And if you don’t understand the statistics beneath the algorithm, you’re building on sand."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html#the-rush-to-the-algorithm",
    "href": "posts/01-why-stats-matter/index.html#the-rush-to-the-algorithm",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "",
    "text": "Did you know?\n\nThe term “regression” comes from Francis Galton’s 1886 study on the heights of parents and children. He noticed that tall parents tended to have slightly shorter children, and short parents had slightly taller ones,they “regressed” toward the average. The name stuck, even though modern regression has nothing to do with shrinking.\n\nThere’s a pattern I see everywhere. Someone discovers machine learning, gets excited, installs scikit-learn or tidymodels, runs a random forest on a dataset, and gets 94% accuracy. Amazing! Ship it!\nBut then someone asks: “Why did your model predict that?” And the answer is… silence.\nThis is what happens when we skip the foundation. Machine learning is not magic,it’s statistics at scale. And if you don’t understand the statistics beneath the algorithm, you’re building on sand."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html#what-beneath-actually-means",
    "href": "posts/01-why-stats-matter/index.html#what-beneath-actually-means",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "What “beneath” actually means",
    "text": "What “beneath” actually means\nEvery machine learning model you’ve ever heard of is built on statistical concepts that have existed for decades:\nLinear regression (1800s) → Neural networks are layers of linear regressions with activation functions stacked on top.\nBayes’ theorem (1763) → The entire field of Bayesian machine learning, spam filters, and medical diagnosis models.\nMatrix multiplication (1850s) → Literally how your data flows through every neural network.\nProbability distributions (1700s) → How models quantify uncertainty, make predictions, and learn from data.\nThe “AI revolution” isn’t new math. It’s old math with new computers."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html#a-simple-example",
    "href": "posts/01-why-stats-matter/index.html#a-simple-example",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "A simple example",
    "text": "A simple example\nLet’s say you want to predict house prices. A machine learning tutorial might tell you to throw your data into XGBoost. But what’s XGBoost actually doing?\nAt its core, it’s fitting a sequence of simple models (like decision trees) where each new model tries to fix the mistakes of the previous ones. The “mistakes” are measured using a loss function,which is a statistical concept. The way it finds the best split in a tree? Variance reduction,another statistical concept.\nLet’s see this with the simplest possible model,a straight line:\n\n\nCode\n# Generate some example data\nset.seed(42)\nn &lt;- 50\nsquare_metres &lt;- runif(n, 40, 200)\nprice &lt;- 50000 + 2500 * square_metres + rnorm(n, 0, 25000)\n\n# Fit the simplest model\nmodel &lt;- lm(price ~ square_metres)\n\n# Plot\nplot(square_metres, price / 1000,\n     pch = 19, col = \"#1a1a2e90\",\n     xlab = \"Size (square metres)\",\n     ylab = \"Price (€ thousands)\",\n     main = \"House Prices: One Line Explains a Lot\",\n     family = \"sans\", cex.main = 1.2)\nabline(model$coefficients[1] / 1000, model$coefficients[2] / 1000,\n       col = \"#e94560\", lwd = 3)\n\n\n\n\n\n\n\n\nFigure 1: A simple linear regression,the foundation beneath complex models\n\n\n\n\n\nThat red line? That’s y = mx + b,something you learned in school. It’s also the building block of neural networks with millions of parameters. The only difference is scale."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html#what-this-blog-will-cover",
    "href": "posts/01-why-stats-matter/index.html#what-this-blog-will-cover",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "What this blog will cover",
    "text": "What this blog will cover\nOver the coming weeks, we’ll build your statistical intuition from the ground up. Each post will focus on one concept, explained so that:\n\nYou understand the why, not just the how\nYou can explain it to someone at a dinner party\nYou see how it connects to the AI/ML topics you care about\n\n\n\n\n\n\n\nTipKey Takeaway\n\n\n\nMachine learning is statistics at scale. Understanding the foundations doesn’t slow you down,it’s what separates someone who uses tools from someone who builds with them."
  },
  {
    "objectID": "posts/01-why-stats-matter/index.html#coming-next-week",
    "href": "posts/01-why-stats-matter/index.html#coming-next-week",
    "title": "Why Statistics Matters Before You Touch Machine Learning",
    "section": "Coming next week",
    "text": "Coming next week\nWhat Data Actually Is,types, distributions, and why the shape of your data matters more than the algorithm you choose.\n\nFound this useful? Share it with someone who’s jumping into ML without the foundations. And follow along,we publish every week."
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "All Articles",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nCategories\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nFebruary 16, 2026\n\n\nExpected Value, Variance, and Why Your Loss Function Is a Statistic\n\n\nfoundations, probability\n\n\n12 min\n\n\n\n\n\n\nFebruary 13, 2026\n\n\nRandom Variables and Distributions: What Your Data Actually Is\n\n\nfoundations, probability\n\n\n10 min\n\n\n\n\n\n\nFebruary 10, 2026\n\n\nWhy Statistics Matters Before You Touch Machine Learning\n\n\nfoundations, machine-learning\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "G\n\n\n\n\nMSc Health Data Science · Bayesian Modelling · Statistical Foundations for ML"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "About me",
    "text": "About me\nI’m a Health Data Science MSc student at the University of Galway, originally from Zimbabwe. I hold a First Class Honours degree in Operations Research and Statistics, and have spent years working as a Monitoring & Evaluation Specialist in the health sector, where I developed a deep appreciation for rigorous data analysis and evidence-based decision making.\nIn 2025, I was selected for the Ireland Fellows Programme, which brought me to Ireland to pursue advanced studies in health data science. My journey through operations research, public health program evaluation, and now Bayesian statistical modelling has taught me that the real power of data science lies not in knowing which algorithm to run, but in understanding why it works.\nI created Stats Beneath because I’ve seen too many talented engineers and data scientists skip over the statistical foundations that make machine learning actually work. This blog is my attempt to bridge that gap, explaining one statistical concept at a time, with clarity, intuition, and real-world context."
  },
  {
    "objectID": "about.html#what-im-working-on",
    "href": "about.html#what-im-working-on",
    "title": "About",
    "section": "What I’m working on",
    "text": "What I’m working on\nMSc Thesis: I’m currently working on small area estimation for malaria prevalence in Ghana using Bayesian hierarchical models. Specifically, I’m implementing BYM2 and ICAR spatial models in Stan to produce district-level prevalence estimates from survey data. This work combines my interests in public health, spatial statistics, and Bayesian inference.\nStats Beneath: This blog, where I publish weekly deep dives into the statistical concepts that power machine learning and AI. Each article starts with intuition, builds to mathematical understanding, and ends with practical takeaways.\nBayesian Explorer: An interactive Shiny application I built to help students and practitioners develop intuition for Bayesian concepts. It visualizes prior-likelihood-posterior relationships and lets you explore how different priors affect inference in real-time. Try it here →"
  },
  {
    "objectID": "about.html#technical-skills",
    "href": "about.html#technical-skills",
    "title": "About",
    "section": "Technical skills",
    "text": "Technical skills\nI work primarily in R for statistical analysis and modeling, using Stan and JAGS for Bayesian inference. I build interactive tools with Shiny, write and publish technical content with Quarto, and handle version control with Git. I also use Python for machine learning workflows and have experience with geospatial analysis (spatial statistics, mapping, GIS workflows).\nMy approach is tool-agnostic but principles-first: I believe understanding the statistical foundations makes you better at choosing the right tool for the job."
  },
  {
    "objectID": "about.html#connect",
    "href": "about.html#connect",
    "title": "About",
    "section": "Connect",
    "text": "Connect\nI’m always interested in connecting with people working at the intersection of statistics, machine learning, and public health.\n\n\nGitHub, code, projects, and open-source contributions\nLinkedIn, professional background and updates\nEmail, reach out directly\n\n\n\nThis site is built with Quarto and deployed on GitHub Pages. All content is written in R Markdown and rendered to HTML. The source code is available on GitHub."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The statistical why behind every ML algorithm",
    "section": "",
    "text": "For ML engineers and data scientists who want to understand the mathematics driving their models, not just tune the hyperparameters. Intuition first, code second.\nNew article every week.\n\nBrowse Articles Subscribe"
  },
  {
    "objectID": "index.html#latest-articles",
    "href": "index.html#latest-articles",
    "title": "The statistical why behind every ML algorithm",
    "section": "Latest Articles",
    "text": "Latest Articles\n\n\n\n\n\nExpected Value, Variance, and Why Your Loss Function Is a Statistic\n\n\n\nfoundations\n\nprobability\n\n\n\nYou minimise loss functions every day. MSE, cross-entropy, MAE — they’re the core of model training. But each one is an expected value in disguise. Understanding that connection changes how you think about every model you build.\n\n\n\n\n\nFeb 16, 2026\n\n\n\n\n\n\n\nRandom Variables and Distributions: What Your Data Actually Is\n\n\n\nfoundations\n\nprobability\n\n\n\nYour dataset isn’t just numbers in a CSV. It’s a realisation of random variables drawn from an unknown distribution. Until you understand that, every model you build is a guess about a process you haven’t described.\n\n\n\n\n\nFeb 13, 2026\n\n\n\n\n\n\n\nWhy Statistics Matters Before You Touch Machine Learning\n\n\n\nfoundations\n\nmachine-learning\n\n\n\nEveryone wants to build AI. But the real superpower isn’t knowing which algorithm to use,it’s understanding why it works.\n\n\n\n\n\nFeb 10, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html",
    "href": "posts/02-random-variables-distributions/index.html",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "",
    "text": "Open any ML tutorial. Step one is always the same: load the data. pd.read_csv('data.csv'). You get a DataFrame. Rows and columns. Numbers.\nAnd then you do things to those numbers. Scale them. Split them. Feed them to a model. Tune hyperparameters. Evaluate. Ship.\nBut here’s the question almost nobody stops to ask: where did those numbers come from?\nNot “which API” or “which database.” I mean: what process generated them? Is each row independent of the others? Could the values have turned out differently if you’d collected data on a different day? If you collected more data tomorrow, would the new rows look like the old ones?\nThese aren’t philosophical questions. They’re statistical ones. And your answers to them,whether you state them explicitly or not,determine whether your model’s predictions mean anything at all.\nThe language for thinking about this clearly is random variables and probability distributions. If you’ve seen these terms in a textbook and moved on, I’d like to show you why they’re not abstract theory,they’re the precise description of what your data is and what your model is trying to learn."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#your-data-has-a-secret-life",
    "href": "posts/02-random-variables-distributions/index.html#your-data-has-a-secret-life",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "",
    "text": "Open any ML tutorial. Step one is always the same: load the data. pd.read_csv('data.csv'). You get a DataFrame. Rows and columns. Numbers.\nAnd then you do things to those numbers. Scale them. Split them. Feed them to a model. Tune hyperparameters. Evaluate. Ship.\nBut here’s the question almost nobody stops to ask: where did those numbers come from?\nNot “which API” or “which database.” I mean: what process generated them? Is each row independent of the others? Could the values have turned out differently if you’d collected data on a different day? If you collected more data tomorrow, would the new rows look like the old ones?\nThese aren’t philosophical questions. They’re statistical ones. And your answers to them,whether you state them explicitly or not,determine whether your model’s predictions mean anything at all.\nThe language for thinking about this clearly is random variables and probability distributions. If you’ve seen these terms in a textbook and moved on, I’d like to show you why they’re not abstract theory,they’re the precise description of what your data is and what your model is trying to learn."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#a-random-variable-is-a-question-not-an-answer",
    "href": "posts/02-random-variables-distributions/index.html#a-random-variable-is-a-question-not-an-answer",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "A random variable is a question, not an answer",
    "text": "A random variable is a question, not an answer\nHere’s the definition you’ll find everywhere: a random variable is a function that maps outcomes from a sample space to real numbers.\nThat’s technically correct and practically useless. Let me give you a better one.\nA random variable is a numerical quantity whose value hasn’t been determined yet.\nBefore you observe your data, you don’t know what values you’ll get. Will this patient’s blood pressure be 120 or 145? Will this customer churn or stay? Will this image contain a cat? You don’t know. But you know the kind of values that are possible, and you may have beliefs about which values are more likely.\nThat’s what a random variable captures: the space of possible values and their relative likelihoods, before you observe anything.\nOnce you observe a value,once the patient’s blood pressure reads 132,that’s no longer a random variable. It’s a realisation. A data point. One draw from the underlying random process.\nYour entire dataset is a collection of realisations. Each row in your DataFrame was, before you observed it, a random variable. Now it’s a fixed number. But the process that generated it is still out there, and it could generate different numbers tomorrow.\nThis is why it matters: your model isn’t trying to memorise your specific 10,000 rows. It’s trying to learn the process that generated them, so it can make predictions about rows it hasn’t seen yet. You can’t do that without thinking about your data as draws from something larger.\n\nThe notation\nStatisticians use uppercase letters for random variables and lowercase for their observed values:\n\n\\(X\\) = the random variable (the question: “what will this patient’s blood pressure be?”)\n\\(x\\) = an observed value, a realisation (the answer: 132)\n\nWhen we write \\(X = x\\), we mean “the random variable \\(X\\) took the value \\(x\\).” When we write \\(P(X = x)\\), we mean “the probability that \\(X\\) takes the value \\(x\\).”\nThis isn’t pedantry. The distinction between \\(X\\) and \\(x\\) is the distinction between the process and the data. Confusing them is how you end up overfitting."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#distributions-the-shape-of-uncertainty",
    "href": "posts/02-random-variables-distributions/index.html#distributions-the-shape-of-uncertainty",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "Distributions: the shape of uncertainty",
    "text": "Distributions: the shape of uncertainty\nIf a random variable describes what could happen, a probability distribution describes how likely each possibility is.\nThink of it as a contract. Before you observe any data, the distribution tells you: “Here are all the possible values, and here’s the relative chance of each one.”\nThere are two flavours, depending on whether the random variable takes countable values or values on a continuum.\n\nDiscrete distributions: counting outcomes\nA discrete random variable takes values you can list: 0, 1, 2, 3, … or {cat, dog, bird}. The probability of each value is given by a probability mass function (PMF):\n\\[P(X = x) = p(x)\\]\nwith two rules: every probability is between 0 and 1, and they all add up to 1.\nThe Bernoulli distribution is the simplest possible distribution. A single trial. Two outcomes. Probability \\(p\\) of success, \\(1-p\\) of failure.\n\\[X \\sim \\text{Bernoulli}(p), \\quad P(X=1) = p, \\quad P(X=0) = 1-p\\]\nEvery binary classification target in your dataset follows a Bernoulli distribution. When your logistic regression outputs \\(\\hat{p} = 0.73\\), it’s estimating the parameter of a Bernoulli distribution. That’s literally what it’s doing,fitting \\(p\\).\nThe Binomial distribution counts the number of successes in \\(n\\) independent Bernoulli trials:\n\\[X \\sim \\text{Binomial}(n, p), \\quad P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\]\nIf you flip a coin 100 times, the number of heads is Binomial. If you classify 100 samples and count the correct ones, the number correct is Binomial (under independence). This is why your model’s accuracy has a sampling distribution,it’s not a fixed number, it’s a draw from a Binomial.\nThe Poisson distribution models the count of events in a fixed interval when events happen at a constant average rate:\n\\[X \\sim \\text{Poisson}(\\lambda), \\quad P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\]\nServer requests per minute. Customer complaints per day. Gene mutations per chromosome. Any time you’re modelling “how many times does something happen,” you’re probably looking at Poisson data.\n\n\nThese distributions are a family\nYou might have noticed something. The Bernoulli is a single yes/no trial. The Binomial counts how many yes’s you get across \\(n\\) independent Bernoulli trials. The Poisson emerges when \\(n\\) gets very large and \\(p\\) gets very small, but the expected count \\(np = \\lambda\\) stays fixed, it’s the limiting case of the Binomial for rare events. These aren’t three unrelated distributions. They’re connected, each one building on the last.\nIt goes deeper than that. The Normal distribution also connects to the Binomial, as \\(n\\) grows, the Binomial converges to a Normal (that’s the Central Limit Theorem at work). And all of these distributions, Bernoulli, Binomial, Poisson, Normal, and several others, belong to a single mathematical family called the exponential family, which turns out to be the foundation of generalised linear models (GLMs). We’ll explore these connections properly in a future article. For now, just know that when you learn one distribution, you’re not learning an isolated fact, you’re learning a node in a network.\n\n\nContinuous distributions: measuring on a continuum\nA continuous random variable takes values on the real line (or an interval). You can’t list all possible values, so you can’t assign a probability to any single value,\\(P(X = 1.23456789...) = 0\\) for any specific number.\nInstead, you describe probabilities over intervals using a probability density function (PDF):\n\\[P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx\\]\nThe PDF \\(f(x)\\) tells you how densely the probability is packed around each value. It’s not a probability itself,it can be greater than 1,but the area under the curve over any interval gives you a probability.\nThe Normal (Gaussian) distribution is the one you know:\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma^2), \\quad f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\\]\nTwo parameters: \\(\\mu\\) (the centre) and \\(\\sigma^2\\) (the spread). It shows up everywhere, and there’s a deep reason for that,the Central Limit Theorem, which we’ll cover in a future article.\nBut here’s what matters for ML: when you assume your regression errors are normally distributed, you’re saying the residuals follow this specific shape. That’s not a trivial assumption. It determines your loss function (MSE corresponds to Gaussian errors), your confidence intervals, and your hypothesis tests. If the assumption is wrong, all of those break.\nThe Uniform distribution assigns equal probability to all values in an interval:\n\\[X \\sim \\text{Uniform}(a, b), \\quad f(x) = \\frac{1}{b-a} \\quad \\text{for } a \\leq x \\leq b\\]\nThis is the distribution of “I have no idea what value to expect.” When you initialise neural network weights uniformly, you’re sampling from this distribution. When you use random search for hyperparameter tuning, you’re drawing from it. It’s the mathematical formalisation of ignorance."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#the-cdf-the-cumulative-view",
    "href": "posts/02-random-variables-distributions/index.html#the-cdf-the-cumulative-view",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "The CDF: the cumulative view",
    "text": "The CDF: the cumulative view\nThe cumulative distribution function (CDF) gives the probability that \\(X\\) is less than or equal to a value:\n\\[F(x) = P(X \\leq x)\\]\nFor discrete random variables, the CDF is a step function. For continuous ones, it’s a smooth curve from 0 to 1. The CDF always exists, even when the PDF doesn’t (for discrete variables), which makes it the more fundamental object.\nWhy should you care? Because when you compute a percentile, a quantile, or a p-value, you’re using the CDF. When you say “this patient’s blood pressure is in the 95th percentile,” you’re saying \\(F(x) = 0.95\\)."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#the-connection-to-ml-you-probably-missed",
    "href": "posts/02-random-variables-distributions/index.html#the-connection-to-ml-you-probably-missed",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "The connection to ML you probably missed",
    "text": "The connection to ML you probably missed\nHere’s where everything clicks.\nEvery supervised learning problem is an attempt to learn a conditional distribution.\nWhen you fit a regression model, you’re estimating:\n\\[P(Y \\mid X) = \\text{some distribution parameterised by } X\\]\nFor linear regression with Gaussian errors, this is:\n\\[Y \\mid X \\sim \\mathcal{N}(X\\beta, \\sigma^2)\\]\nFor logistic regression:\n\\[Y \\mid X \\sim \\text{Bernoulli}(\\sigma(X\\beta))\\]\nFor Poisson regression:\n\\[Y \\mid X \\sim \\text{Poisson}(\\exp(X\\beta))\\]\nIn each case, \\(X\\) (the features) determine the parameters of the distribution, and \\(Y\\) (the target) is a random draw from that distribution. The model doesn’t predict \\(Y\\) directly,it predicts the distribution of \\(Y\\), and the point prediction is just a summary (usually the mean).\nThis is why understanding distributions isn’t optional for ML. You’re fitting them whether you know it or not. sklearn just hides it from you.\n\nThe loss function is the distribution\nThis connection goes even deeper. Your choice of loss function implicitly assumes a distribution:\n\n\n\nLoss Function\nImplicit Distribution\nLink\n\n\n\n\nMean Squared Error\nNormal (Gaussian)\nIdentity\n\n\nCross-Entropy\nBernoulli / Categorical\nLogit / Softmax\n\n\nPoisson Deviance\nPoisson\nLog\n\n\nHuber Loss\nA compromise: Normal near 0, Laplace in the tails\n,\n\n\n\nWhen you minimise MSE, you’re doing maximum likelihood estimation under the assumption that your errors are Gaussian. When you minimise cross-entropy, you’re doing MLE under the assumption that your targets are Bernoulli.\nIf you’ve ever wondered “why MSE for regression and cross-entropy for classification?”,this is the answer. It’s not arbitrary. Each loss function is derived from a distributional assumption about the target variable. We’ll make this precise when we cover likelihood in a future article."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#what-this-means-in-practice",
    "href": "posts/02-random-variables-distributions/index.html#what-this-means-in-practice",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "What this means in practice",
    "text": "What this means in practice\nUnderstanding random variables and distributions gives you three practical superpowers:\n1. You can diagnose model failures. If your regression residuals aren’t approximately normal, MSE might not be the right loss. If your count data has more zeros than Poisson allows, you need a zero-inflated model. If your binary classifier’s predicted probabilities don’t match observed frequencies, it’s miscalibrated. All of these diagnoses require understanding the distributional assumptions you’ve made.\n2. You can quantify uncertainty. A prediction of \\(\\hat{y} = 42\\) is useless without knowing how confident you are. If you know the distribution, you can compute prediction intervals, confidence intervals, and posterior distributions. Without it, you’re flying blind.\n3. You can choose the right model. Gaussian targets → linear regression (or ridge, lasso). Binary targets → logistic regression. Count targets → Poisson regression. Skewed positive targets → Gamma regression. Bounded proportions → Beta regression. The distribution of your target variable tells you which model family to use."
  },
  {
    "objectID": "posts/02-random-variables-distributions/index.html#the-mental-model-to-take-away",
    "href": "posts/02-random-variables-distributions/index.html#the-mental-model-to-take-away",
    "title": "Random Variables and Distributions: What Your Data Actually Is",
    "section": "The mental model to take away",
    "text": "The mental model to take away\nHere’s the shift I want you to make:\nBefore: “I have data in a CSV. I’ll fit a model to it.”\nAfter: “My data is a sample of realisations from an unknown data-generating process. My model is a hypothesis about what that process looks like. Training is estimating the parameters of that process. Evaluation is checking whether my hypothesis is consistent with new realisations.”\nThat second framing is what statistics gives you. It’s more precise, more honest, and it leads to better models.\nNext week, we’ll build on this foundation. You now know that your data comes from distributions and your models estimate distributions. But what exactly are you estimating when you compute a mean, a variance, or a loss? That’s the world of expected values,and it turns out your loss function is one.\n\nThis is article 2 of Stats Beneath, a weekly series on the statistical foundations of machine learning. Subscribe to get each article when it’s published."
  }
]